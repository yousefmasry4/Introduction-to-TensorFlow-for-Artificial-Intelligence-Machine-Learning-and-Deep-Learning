{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (6, 1) was passed for an output of shape (None, 5) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-219ddb24f967>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m500\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/LSTM/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[1;32m    817\u001B[0m         \u001B[0mmax_queue_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    818\u001B[0m         \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 819\u001B[0;31m         use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[1;32m    820\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    821\u001B[0m   def evaluate(self,\n",
      "\u001B[0;32m~/anaconda3/envs/LSTM/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[1;32m    233\u001B[0m           \u001B[0mmax_queue_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    234\u001B[0m           \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 235\u001B[0;31m           use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[1;32m    236\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m       \u001B[0mtotal_samples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_get_total_number_of_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraining_data_adapter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/LSTM/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001B[0m in \u001B[0;36m_process_training_inputs\u001B[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m    591\u001B[0m         \u001B[0mmax_queue_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    592\u001B[0m         \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 593\u001B[0;31m         use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[1;32m    594\u001B[0m     \u001B[0mval_adapter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/LSTM/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001B[0m in \u001B[0;36m_process_inputs\u001B[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m    644\u001B[0m     \u001B[0mstandardize_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    645\u001B[0m     x, y, sample_weights = standardize(\n\u001B[0;32m--> 646\u001B[0;31m         x, y, sample_weight=sample_weights)\n\u001B[0m\u001B[1;32m    647\u001B[0m   \u001B[0;32melif\u001B[0m \u001B[0madapter_cls\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mdata_adapter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mListsOfScalarsDataAdapter\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    648\u001B[0m     \u001B[0mstandardize_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstandardize\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/LSTM/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001B[0m in \u001B[0;36m_standardize_user_data\u001B[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001B[0m\n\u001B[1;32m   2381\u001B[0m         \u001B[0mis_dataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2382\u001B[0m         \u001B[0mclass_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclass_weight\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2383\u001B[0;31m         batch_size=batch_size)\n\u001B[0m\u001B[1;32m   2384\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2385\u001B[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001B[0;32m~/anaconda3/envs/LSTM/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001B[0m in \u001B[0;36m_standardize_tensors\u001B[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001B[0m\n\u001B[1;32m   2487\u001B[0m           \u001B[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2488\u001B[0m           training_utils.check_loss_and_target_compatibility(\n\u001B[0;32m-> 2489\u001B[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001B[0m\u001B[1;32m   2490\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2491\u001B[0m       sample_weights, _, _ = training_utils.handle_partial_sample_weights(\n",
      "\u001B[0;32m~/anaconda3/envs/LSTM/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001B[0m in \u001B[0;36mcheck_loss_and_target_compatibility\u001B[0;34m(targets, loss_fns, output_shapes)\u001B[0m\n\u001B[1;32m    808\u001B[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001B[1;32m    809\u001B[0m                            \u001B[0;34m' was passed for an output of shape '\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 810\u001B[0;31m                            \u001B[0;34m' while using as loss `'\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mloss_name\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'`. '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    811\u001B[0m                            \u001B[0;34m'This loss expects targets to have the same shape '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    812\u001B[0m                            'as the output.')\n",
      "\u001B[0;31mValueError\u001B[0m: A target array with shape (6, 1) was passed for an output of shape (None, 5) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "model.fit(xs, ys, epochs=500)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.999908]]\n",
      "[array([[1.9999868]], dtype=float32), array([-0.99996006], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([10.0]))\n",
    "print(model.get_weights())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}